Instructions for web scraping code
INSTALLATION
1. Ensure you have the current version of python installed (this code was written in Python 3). Download and install python: https://www.python.org/downloads/
IMPORTANT:
Make sure to add Python as a Path to your computer’s environment. This is usually a check-box in the installation process. Some info on this is here https://datatofish.com/add-python-to-windows-path/ 

2. Get a Figshare API Personal Token: https://help.figshare.com/article/how-to-get-a-personal-token 
There is a place to input your personal token as the top of the scrape script. The token is the security authorisation to access the figshare website and the code will not work without it

3. The database created by this code is and SQL database written in Python using the open source SQLite software. Download and install SQLite: https://www.sqlite.org/download.html 

4. Additional Python libraries that must be installed are sqlite3 and swaggerpy. These can be installed in the command window if a Python path has been added. To use pip install, ensure to change directory in your command window to your local python location, usually: C:\Users\UserName\AppData\Local\Programs\Python\Python39 for example.

Install sqlite3 for python: https://pypi.org/project/db-sqlite3/ 
Install swaggerpy for python: https://pypi.org/project/swaggerpy/ 

OPERATION
1. Unzip the code and save the scripts in a master folder. Copy and paste the 2 scripts (figshare_search.py and databaser.py) and the swagger_client folder into the folder you want to work from.

2. Run the figshare_search.py code first. Follow the steps (1-3) within the code.

3. Next run the databaser.py code. Follow steps 1-3 within the code.

4. After running these two scripts, you will have a set of downloaded supplementary files labelled by the figshare article number and file download ID. These are also stored in the sqlite database you created in the figshare_search.py script. 

5. Clean the data to ensure the column headers are consistent across all files. See Martin et al. (2021) for guidelines. Save the data files as csv files with UTF-8 encoding

6. Run the data_to_sql_database.py code. Follow the instructions within the code to build on the database from Martin et al. (2021) or to create your own new database.

DATA AVAILABILITY:


